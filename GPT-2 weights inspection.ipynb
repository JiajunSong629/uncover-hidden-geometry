{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from transformers import logging\n",
    "from transformers import set_seed\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "set_seed(2023)\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "save_dir = 'Figs_GPT2_inspect'\n",
    "def create_folder(dir):\n",
    "    if not os.path.isdir(dir):\n",
    "        os.mkdir(dir)\n",
    "create_folder(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(\"gpt2\", return_dict_in_generate=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġwhistleblower',\n",
       " 'ĠRevelations',\n",
       " 'ileaks',\n",
       " 'Snow',\n",
       " 'Ġleak',\n",
       " 'Ġcompromised',\n",
       " 'Ġleaking',\n",
       " 'ĠPastebin',\n",
       " 'ĠEcuador',\n",
       " 'Leaks',\n",
       " 'Ġsubpoena',\n",
       " 'hack',\n",
       " 'ash',\n",
       " 'Ġwhistle',\n",
       " 'ĠDisclosure',\n",
       " 'Ġadversary',\n",
       " 'Ġdiscl',\n",
       " 'Ġleaks',\n",
       " 'Ġhacked',\n",
       " 'andals']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_top = 20\n",
    "layer = 10\n",
    "mlp = gpt2.transformer.h[layer].mlp\n",
    "final_lin_layer = gpt2.lm_head\n",
    "\n",
    "idx = 40\n",
    "\n",
    "v = mlp.c_proj.weight[idx,:]\n",
    "scores = final_lin_layer(v).numpy(force=True)\n",
    "\n",
    "tmp = np.argsort(scores)[::-1]\n",
    "tokenizer.convert_ids_to_tokens(tmp[:num_top])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
